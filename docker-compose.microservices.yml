services:
  # ============================================
  # API Gateway - Orquestador central
  # ============================================
  gateway:
    build:
      context: ./services
      dockerfile: gateway/Dockerfile
    container_name: synth-gateway
    ports:
      - "8000:8000"
    environment:
      - DEPTH_SERVICE_URL=http://depth:8001
      - SEGMENTATION_SERVICE_URL=http://segmentation:8002
      - EFFECTS_SERVICE_URL=http://effects:8003
      - AUGMENTOR_SERVICE_URL=http://augmentor:8004
      - DOMAIN_GAP_SERVICE_URL=http://domain_gap:8005
      - PYTHONUNBUFFERED=1
      # Rutas por defecto para datasets
      - BACKGROUNDS_PATH=/app/datasets/Backgrounds_filtered
      - OBJECTS_PATH=/app/datasets/Objects
      # Job database path
      - JOBS_DB_PATH=/shared/db/jobs.db
      # Filesystem endpoints configuration
      - DATA_BASE_PATH=/app/datasets
      - DATA_DIR=/app/datasets
      - DATASETS_DIR=/app/datasets
      - UPLOADS_DIR=/app/datasets/uploads
      - OUTPUT_PATH=/app/output
      # Domain configuration paths
      - DOMAINS_PATH=/app/config/domains
      - USER_DOMAINS_PATH=/shared/domains
    volumes:
      - shared_data:/shared
      - jobs_db:/shared/db
      # Dataset con Backgrounds_filtered/ y Objects/
      # Configura DATASET_PATH en .env.microservices
      - ${DATASET_PATH:-./datasets}:/app/datasets:rw
      # Domain configurations (built-in)
      - ./config/domains:/app/config/domains:ro
    # Límites de recursos - hardware potente (96GB RAM, Core Ultra 9 - 24 cores)
    mem_limit: 4G
    memswap_limit: 4G
    cpus: 2
    depends_on:
      depth:
        condition: service_healthy
      effects:
        condition: service_healthy
      augmentor:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/ping', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Depth Service - Depth-Anything-3
  # ============================================
  depth:
    build:
      context: ./services
      dockerfile: depth/Dockerfile
    container_name: synth-depth
    ports:
      - "8001:8001"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEPTH_MODEL=${DEPTH_MODEL:-DA3-BASE}
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:False,garbage_collection_threshold:0.7
      - PYTHONUNBUFFERED=1
      - HF_HOME=/app/checkpoints/huggingface
    volumes:
      - shared_data:/shared
      - checkpoints:/app/checkpoints
    # Límites de recursos - RTX 5090 32GB VRAM (CPU reducido: 4 de 24 cores)
    mem_limit: 12G
    memswap_limit: 12G
    cpus: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Segmentation Service - SAM3
  # ============================================
  segmentation:
    build:
      context: ./services
      dockerfile: segmentation/Dockerfile
    container_name: synth-segmentation
    ports:
      - "8002:8002"
    env_file:
      - .env
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - HF_HOME=/app/checkpoints/huggingface
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:False,garbage_collection_threshold:0.7
      - PYTHONUNBUFFERED=1
      # Job database path
      - JOBS_DB_PATH=/shared/db/jobs.db
    volumes:
      - shared_data:/shared
      - jobs_db:/shared/db
      - checkpoints:/app/checkpoints
      # Dataset para lectura de imagenes (extraccion de objetos)
      - ${DATASET_PATH:-./datasets}:/app/datasets:rw
      # Output para objetos extraidos (escritura)
      - ./output:/app/output
    # Límites de recursos - RTX 5090 32GB VRAM (CPU reducido: 4 de 24 cores)
    mem_limit: 12G
    memswap_limit: 12G
    cpus: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      # Service uses lazy loading - health check passes immediately
      # SAM3 model loads in background (check /model-status endpoint)
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8002/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s  # Fast startup with lazy SAM3 loading
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Effects Service - Realism Pipeline
  # ============================================
  effects:
    build:
      context: ./services
      dockerfile: effects/Dockerfile
    container_name: synth-effects
    ports:
      - "8003:8003"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - shared_data:/shared
      - caustics_cache:/app/cache
    # Límites de recursos - sin GPU
    mem_limit: 4G
    memswap_limit: 4G
    cpus: 2
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8003/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Augmentor Service - Composition + Validation
  # ============================================
  augmentor:
    build:
      context: .
      dockerfile: services/augmentor/Dockerfile
    container_name: synth-augmentor
    ports:
      - "8004:8004"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEPTH_SERVICE_URL=http://depth:8001
      - EFFECTS_SERVICE_URL=http://effects:8003
      - SEGMENTATION_SERVICE_URL=http://segmentation:8002
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:False,garbage_collection_threshold:0.7
      - PYTHONUNBUFFERED=1
      # Job database path
      - JOBS_DB_PATH=/shared/db/jobs.db
    volumes:
      - shared_data:/shared
      - jobs_db:/shared/db
      - checkpoints:/app/checkpoints
      # Dataset con Backgrounds_filtered/ y Objects/
      - ${DATASET_PATH:-./datasets}:/app/datasets:rw
      # Output para imágenes generadas
      - ./output:/app/output
    # Límites de recursos - SERVICIO CRÍTICO (RTX 5090, 96GB RAM, 24 cores)
    mem_limit: 24G
    memswap_limit: 24G
    cpus: 8
    shm_size: 8G  # Aumentado para operaciones GPU compartidas
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      depth:
        condition: service_healthy
      effects:
        condition: service_healthy
      segmentation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8004/health', timeout=5)"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Domain Gap - Metrics & Reduction
  # ============================================
  domain_gap:
    build:
      context: .
      dockerfile: services/domain_gap/Dockerfile
    container_name: synth-domain-gap
    ports:
      - "8005:8005"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:False,garbage_collection_threshold:0.7
      - PYTHONUNBUFFERED=1
      - JOBS_DB_PATH=/shared/db/jobs.db
      - HF_HOME=/app/checkpoints/huggingface
      - REFERENCES_DIR=/shared/references
    volumes:
      - shared_data:/shared
      - jobs_db:/shared/db
      - checkpoints:/app/checkpoints
      - ${DATASET_PATH:-./datasets}:/app/datasets:rw
      - ./output:/app/output
      - ./config:/app/config:ro
    mem_limit: 16G
    memswap_limit: 16G
    cpus: 4
    shm_size: 4G
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      depth:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8005/ping', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - synth-network
    restart: unless-stopped

  # ============================================
  # Frontend - Vue.js Modern UI (Principal)
  # ============================================
  # Nginx sirve el frontend y actúa como reverse proxy para las APIs:
  #   /api/*           -> gateway:8000
  #   /segmentation/*  -> segmentation:8002
  frontend:
    build:
      context: ./frontend-vue
      dockerfile: Dockerfile
    container_name: synth-frontend
    ports:
      - "3000:3000"
    # No se necesitan variables VITE_* - nginx hace proxy a las APIs internas
    # Límites de recursos - interfaz web ligera (nginx sirve archivos estáticos)
    mem_limit: 256M
    memswap_limit: 256M
    cpus: 0.5
    depends_on:
      gateway:
        condition: service_healthy
      segmentation:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - synth-network
    restart: unless-stopped

networks:
  synth-network:
    driver: bridge
    name: synth-network

# ============================================
# Volúmenes compartidos para transferencia eficiente
# ============================================
volumes:
  shared_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${SHARED_DATA_PATH:-./volumes/shared}
  checkpoints:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${CHECKPOINTS_PATH:-./volumes/checkpoints}
  caustics_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${CACHE_PATH:-./volumes/cache}
  # Job database for persistence across restarts
  jobs_db:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${JOBS_DB_VOLUME_PATH:-./volumes/db}
