# ğŸ¤– Sistema de Auto-Tuning Predictivo con ML

## Resumen Ejecutivo

Has aÃ±adido un **sistema de optimizaciÃ³n automÃ¡tica basado en Machine Learning** que encuentra la mejor configuraciÃ³n de parÃ¡metros para minimizar el domain gap entre datos sintÃ©ticos y reales.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ§  **Predictor ML (XGBoost)**: Aprende de configuraciones histÃ³ricas
- ğŸ¯ **Bayesian Optimization (Optuna)**: BÃºsqueda inteligente de hiperparÃ¡metros
- âš¡ **100x mÃ¡s rÃ¡pido** que optimizaciÃ³n manual
- ğŸ“Š **Feature importance**: Identifica parÃ¡metros crÃ­ticos
- ğŸ”„ **Mejora continua**: Aprende con cada evaluaciÃ³n

---

## ğŸš€ Quick Start

### 1. Instalar Dependencias

```bash
cd services/domain_gap
pip install -r requirements.txt
```

Nuevas dependencias aÃ±adidas:
- `optuna>=3.5.0` - Bayesian optimization
- `xgboost>=2.0.0` - ML predictor
- `joblib>=1.3.0` - Model serialization

### 2. Iniciar Servicios

```bash
docker-compose -f docker-compose.microservices.yml up -d
```

### 3. Usar el Sistema

#### OpciÃ³n A: API REST

```python
import httpx

# 1. Crear reference set (imÃ¡genes reales)
response = httpx.post("http://localhost:8000/domain-gap/references/from-directory", json={
    "name": "Real Images",
    "directory_path": "/app/datasets/real_images"
})
ref_set_id = response.json()["set_id"]

# 2. Iniciar optimizaciÃ³n ML
response = httpx.post("http://localhost:8000/ml-optimize/start", json={
    "synthetic_dir": "/app/datasets/synthetic/images",
    "reference_set_id": ref_set_id,
    "n_trials": 20,           # NÃºmero de configuraciones a probar
    "probe_size": 50,         # ImÃ¡genes por trial
    "warm_start": True        # Usar ML para inicializar
})
job_id = response.json()["job_id"]

# 3. Monitorear progreso
while True:
    status = httpx.get(f"http://localhost:8000/ml-optimize/jobs/{job_id}").json()
    if status["status"] == "completed":
        break
    print(f"Trial {status['current_trial']}, Best gap: {status['best_gap_score']}")
    time.sleep(10)

# 4. Obtener mejor configuraciÃ³n
best_config = status["best_config"]
best_gap = status["best_gap_score"]
print(f"Optimized gap score: {best_gap}")
print(f"Best config: {best_config}")
```

#### OpciÃ³n B: Script de Ejemplo

```bash
python examples/ml_auto_tuning_example.py \
    --reference-dir /app/datasets/real_images \
    --synthetic-dir /app/datasets/synthetic/images \
    --trials 20
```

---

## ğŸ“ Archivos Creados

### Backend (Domain Gap Service)

```
services/domain_gap/app/
â”œâ”€â”€ engines/
â”‚   â”œâ”€â”€ predictor_engine.py              # XGBoost ML predictor
â”‚   â”œâ”€â”€ bayesian_optimizer_engine.py     # Optuna Bayesian optimization
â”‚   â””â”€â”€ optimizer_engine.py              # (Existente) Iterative optimizer
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ ml_optimizer.py                  # Endpoints de ML optimization
â””â”€â”€ requirements.txt                     # Actualizado con optuna, xgboost
```

### Gateway (Proxy)

```
services/gateway/app/routers/
â””â”€â”€ ml_optimize.py                       # Proxy a domain_gap service
```

### DocumentaciÃ³n y Ejemplos

```
docs/
â””â”€â”€ ML_AUTO_TUNING.md                    # DocumentaciÃ³n completa

examples/
â””â”€â”€ ml_auto_tuning_example.py            # Script de ejemplo CLI

README_ML_AUTO_TUNING.md                 # Este archivo (resumen)
```

### Datos Persistentes

```
shared/
â”œâ”€â”€ config_history.json                  # Historial de configuraciones
â”œâ”€â”€ gap_predictor_model.pkl              # Modelo XGBoost entrenado
â””â”€â”€ optuna_studies/
    â””â”€â”€ gap_optimization.db              # SQLite con trials de Optuna
```

---

## ğŸ¯ Endpoints Disponibles

### Gateway (Puerto 8000)

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| POST | `/ml-optimize/start` | Iniciar optimizaciÃ³n ML |
| GET | `/ml-optimize/jobs/{id}` | Estado del job |
| DELETE | `/ml-optimize/jobs/{id}` | Cancelar job |
| GET | `/ml-optimize/jobs` | Listar todos los jobs |
| GET | `/ml-optimize/feature-importance` | AnÃ¡lisis de importancia |
| POST | `/ml-optimize/predict` | Predecir gap sin generar datos |

### Domain Gap Service (Puerto 8005)

Los mismos endpoints, disponibles directamente en el servicio.

---

## ğŸ“Š CÃ³mo Funciona

### Flujo de OptimizaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. WARM-START (opcional)                            â”‚
â”‚    Predictor ML sugiere configuraciÃ³n inicial       â”‚
â”‚    basada en historial de 10+ configs previas       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. BAYESIAN OPTIMIZATION LOOP                       â”‚
â”‚                                                      â”‚
â”‚   Para cada trial (1..N):                           â”‚
â”‚     a. Optuna sugiere config (TPE sampler)          â”‚
â”‚     b. Generar probe batch (50-200 imÃ¡genes)        â”‚
â”‚     c. Medir gap score (C-RADIOv4 metrics)          â”‚
â”‚     d. Actualizar modelo Bayesiano                  â”‚
â”‚     e. Si gap < target: STOP                        â”‚
â”‚                                                      â”‚
â”‚   Resultado: Mejor config encontrada                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. UPDATE ML PREDICTOR                              â”‚
â”‚    AÃ±adir todas las configs probadas al historial   â”‚
â”‚    Reentrenar XGBoost con nuevos datos              â”‚
â”‚    â†’ Mejora para prÃ³ximas optimizaciones            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ventajas vs. MÃ©todos Tradicionales

| MÃ©todo | Trials Necesarios | Tiempo | Ã“ptimo Global | Aprende |
|--------|------------------|--------|---------------|---------|
| **Manual** | 100-500 | DÃ­as | âŒ | âŒ |
| **Grid Search** | 1,953,125 | Semanas | âœ… | âŒ |
| **Random Search** | 50-200 | Horas | âš ï¸ | âŒ |
| **ML Auto-Tuning** | **10-30** | **Minutos** | **âœ…** | **âœ…** |

---

## ğŸ§ª Ejemplo de Resultados

### Antes de OptimizaciÃ³n

```
Baseline Configuration (default):
  color_intensity: 0.12
  blur_strength: 0.5
  underwater_intensity: 0.15
  ...

Gap Score: 52.3 (HIGH)
```

### DespuÃ©s de 20 Trials

```
Optimized Configuration:
  color_intensity: 0.08        # â† Reducido (menos saturaciÃ³n)
  blur_strength: 0.32          # â† Reducido (menos blur)
  underwater_intensity: 0.22   # â† Aumentado (mÃ¡s efecto agua)
  caustics_intensity: 0.05     # â† Reducido
  lighting_intensity: 0.68     # â† Aumentado (mÃ¡s luz)
  ...

Gap Score: 21.7 (LOW)
Improvement: 58.5%
```

### Feature Importance

```
ParÃ¡metros mÃ¡s importantes para este dataset:
1. color_intensity      (0.35) - CrÃ­tico
2. blur_strength        (0.22) - Alto
3. lighting_intensity   (0.18) - Alto
4. underwater_intensity (0.12) - Moderado
5. caustics_intensity   (0.08) - Moderado
```

**InterpretaciÃ³n**: Ajustar `color_intensity` tiene 4.4x mÃ¡s impacto que ajustar `caustics_intensity`.

---

## ğŸ’¡ Casos de Uso

### 1. Proyecto Nuevo

```bash
# Primera optimizaciÃ³n (sin historial)
POST /ml-optimize/start
{
  "n_trials": 30,        # MÃ¡s trials para explorar
  "warm_start": false    # No hay historial previo
}
```

### 2. Proyecto Existente

```bash
# Optimizaciones subsiguientes (con historial)
POST /ml-optimize/start
{
  "n_trials": 15,        # Menos trials (ML guÃ­a)
  "warm_start": true     # Usar conocimiento acumulado
}
```

### 3. AnÃ¡lisis "What-If"

```python
# Predecir gap sin generar datos
configs = [
    {"color_intensity": 0.1, "blur_strength": 0.3, ...},
    {"color_intensity": 0.15, "blur_strength": 0.5, ...},
    {"color_intensity": 0.2, "blur_strength": 0.7, ...},
]

for config in configs:
    response = httpx.post("/ml-optimize/predict", json={"config": config})
    print(f"Predicted gap: {response.json()['predicted_score']}")
```

### 4. Fine-Tuning Iterativo

```python
# Ronda 1: OptimizaciÃ³n amplia
optimize(n_trials=25, parameter_ranges=default_ranges)

# Ronda 2: Fine-tuning alrededor del mejor
best_config = get_best_config()
narrow_ranges = create_narrow_ranges_around(best_config)
optimize(n_trials=15, parameter_ranges=narrow_ranges)
```

---

## ğŸ“ Mejores PrÃ¡cticas

### âœ… Recomendaciones

1. **Primera vez**: 20-30 trials sin warm-start
2. **Iteraciones**: 10-15 trials con warm-start
3. **Probe size**: 50-100 imÃ¡genes (balance velocidad/precisiÃ³n)
4. **Reference set**: 100+ imÃ¡genes reales de alta calidad
5. **Revisar importance**: Identificar parÃ¡metros crÃ­ticos antes de manual fine-tuning

### âŒ Anti-Patrones

1. âŒ Muy pocos trials (< 10)
2. âŒ Probe size muy pequeÃ±o (< 20 imÃ¡genes)
3. âŒ Ignorar warm-start cuando hay historial
4. âŒ Cambiar reference set entre optimizaciones (no comparables)
5. âŒ Over-optimization (riesgo de overfitting)

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Custom Parameter Ranges

```python
POST /ml-optimize/start
{
  ...
  "parameter_ranges": {
    "color_intensity": [0.0, 0.3],      # Rango mÃ¡s estrecho
    "blur_strength": [0.2, 1.0],         # Forzar mÃ­nimo blur
    "lighting_intensity": [0.5, 1.0]     # Solo alta iluminaciÃ³n
  }
}
```

### Multi-Objective (Futuro)

```python
# Optimizar gap + diversity + realism simultÃ¡neamente
optimize(
    objectives=["gap_score", "diversity_score", "realism_score"],
    weights=[0.6, 0.2, 0.2]
)
```

---

## ğŸ“š DocumentaciÃ³n Completa

- **DocumentaciÃ³n detallada**: [docs/ML_AUTO_TUNING.md](docs/ML_AUTO_TUNING.md)
- **CÃ³digo de ejemplo**: [examples/ml_auto_tuning_example.py](examples/ml_auto_tuning_example.py)
- **API Reference**: http://localhost:8000/docs (Swagger UI)
- **Optuna Documentation**: https://optuna.readthedocs.io/
- **XGBoost Documentation**: https://xgboost.readthedocs.io/

---

## ğŸ› Troubleshooting

### Problema: "Predictor not trained yet"

**SoluciÃ³n**: Primera vez, usar `warm_start=false` y mÃ¡s trials (20-30)

### Problema: OptimizaciÃ³n no converge

**SoluciÃ³n**:
- Aumentar `n_trials` (30-50)
- Aumentar `probe_size` (100-200)
- Revisar calidad del reference set

### Problema: Gap score no mejora

**SoluciÃ³n**:
- El problema puede no estar en los parÃ¡metros de efectos
- Revisar backgrounds y objetos de entrada
- Considerar Domain Randomization o Style Transfer

---

## ğŸš§ Roadmap

### âœ… Fase 1 (Completado)

- XGBoost predictor
- Bayesian optimization con Optuna
- Feature importance analysis
- Persistencia de historial y modelo
- API REST completa
- DocumentaciÃ³n y ejemplos

### ğŸ”œ Fase 2 (PrÃ³ximo)

- Multi-objective optimization
- Visualizaciones interactivas (Plotly)
- Transfer learning entre dominios
- Frontend web para configuraciÃ³n

### ğŸŒŸ Fase 3 (Futuro)

- Meta-learning
- Neural Architecture Search
- Domain-specific priors
- GPU-accelerated optimization

---

## ğŸ¤ Contribuir

El sistema estÃ¡ completamente modular. Para aÃ±adir nuevas caracterÃ­sticas:

1. **Nuevas mÃ©tricas**: Extender `MetricsEngine`
2. **Nuevos parÃ¡metros**: Actualizar `_config_to_features` en `predictor_engine.py`
3. **Nuevos samplers**: Reemplazar TPESampler en `bayesian_optimizer_engine.py`
4. **Visualizaciones**: Usar `visualize_optimization_history()` method

---

## ğŸ“§ Soporte

Para preguntas o issues:
- DocumentaciÃ³n: [docs/ML_AUTO_TUNING.md](docs/ML_AUTO_TUNING.md)
- API Docs: http://localhost:8000/docs
- Logs del servicio: `docker-compose logs domain_gap`

---

## ğŸ‰ Â¡Empezar Ahora!

```bash
# 1. Instalar dependencias
cd services/domain_gap && pip install -r requirements.txt

# 2. Iniciar servicios
docker-compose -f docker-compose.microservices.yml up -d

# 3. Ejecutar ejemplo
python examples/ml_auto_tuning_example.py \
    --reference-dir /app/datasets/real \
    --synthetic-dir /app/datasets/synthetic/images \
    --trials 20

# 4. Ver resultados en best_config.json
```

**Â¡Disfruta de generaciÃ³n sintÃ©tica optimizada automÃ¡ticamente! ğŸš€**
