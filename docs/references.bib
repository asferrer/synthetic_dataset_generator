% =============================================================================
% references.bib â€” Synthetic Dataset Generator
% 41 scientific papers used or consulted for the development of this tool
% Organized in 12 categories (A-L)
% =============================================================================


% =============================================================================
% A. DEPTH ESTIMATION
% =============================================================================

% Depth Anything - Main depth estimation model
@InProceedings{yang2024depthanything,
    author    = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
    title     = {Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2024},
    note      = {arXiv:2401.10891}
}

% Depth Anything V2 - Improved version
@InProceedings{yang2024depthanythingv2,
    author    = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
    title     = {Depth Anything V2},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2024},
    note      = {arXiv:2406.09414}
}


% =============================================================================
% B. SEGMENTATION
% =============================================================================

% SAM - Main segmentation model
@InProceedings{kirillov2023segment,
    author    = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollar, Piotr and Girshick, Ross},
    title     = {Segment Anything},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {4015--4026}
}

% SAM 2 - Segment Anything in images and video
@InProceedings{ravi2025sam2,
    author    = {Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
    title     = {{SAM} 2: Segment Anything in Images and Videos},
    booktitle = {International Conference on Learning Representations (ICLR)},
    year      = {2025},
    note      = {Best Paper Honorable Mention. arXiv:2408.00714}
}

% Mask2Former - Universal image segmentation
@InProceedings{cheng2022mask2former,
    author    = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G. and Kirillov, Alexander and Girdhar, Rohit},
    title     = {Masked-Attention Mask Transformer for Universal Image Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {1290--1299},
    note      = {arXiv:2112.01527}
}


% =============================================================================
% C. IMAGE QUALITY METRICS
% =============================================================================

% FID - Main metric in domain_gap service
@InProceedings{heusel2017gans,
    author    = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
    title     = {{GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}},
    booktitle = {Advances in Neural Information Processing Systems},
    volume    = {30},
    pages     = {6626--6637},
    year      = {2017},
    note      = {arXiv:1706.08500}
}

% KID - Complementary metric to FID
@InProceedings{binkowski2018demystifying,
    author    = {Bi\'{n}kowski, Miko{\l}aj and Sutherland, Danica J. and Arbel, Michael and Gretton, Arthur},
    title     = {{Demystifying MMD GANs}},
    booktitle = {International Conference on Learning Representations (ICLR)},
    year      = {2018},
    url       = {https://openreview.net/forum?id=r1lUOzWCW},
    note      = {arXiv:1801.01401}
}

% LPIPS - Perceptual quality validation in augmentor
@InProceedings{zhang2018unreasonable,
    author    = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
    title     = {{The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {586--595},
    year      = {2018},
    doi       = {10.1109/CVPR.2018.00068},
    note      = {arXiv:1801.03924}
}

% SSIM - Structural similarity metric
@Article{wang2004image,
    author    = {Wang, Zhou and Bovik, Alan C. and Sheikh, Hamid R. and Simoncelli, Eero P.},
    title     = {Image Quality Assessment: From Error Visibility to Structural Similarity},
    journal   = {IEEE Transactions on Image Processing},
    volume    = {13},
    number    = {4},
    pages     = {600--612},
    year      = {2004},
    doi       = {10.1109/TIP.2003.819861}
}


% =============================================================================
% D. GENERATIVE MODELS AND STYLE TRANSFER
% =============================================================================

% GAN - Foundational paper
@InProceedings{goodfellow2014generative,
    author    = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    title     = {{Generative Adversarial Nets}},
    booktitle = {Advances in Neural Information Processing Systems},
    volume    = {27},
    pages     = {2672--2680},
    year      = {2014},
    note      = {arXiv:1406.2661}
}

% CycleGAN - Unpaired image-to-image translation (domain_gap service)
@InProceedings{zhu2017unpaired,
    author    = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
    title     = {{Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}},
    booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
    pages     = {2242--2251},
    year      = {2017},
    doi       = {10.1109/ICCV.2017.244},
    note      = {arXiv:1703.10593}
}

% Pix2Pix - Paired image-to-image translation
@InProceedings{isola2017image,
    author    = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
    title     = {{Image-to-Image Translation with Conditional Adversarial Networks}},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {5967--5976},
    year      = {2017},
    doi       = {10.1109/CVPR.2017.632},
    note      = {arXiv:1611.07004}
}

% Neural Style Transfer (domain_gap service)
@InProceedings{gatys2016image,
    author    = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
    title     = {{Image Style Transfer Using Convolutional Neural Networks}},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {2414--2423},
    year      = {2016},
    doi       = {10.1109/CVPR.2016.265}
}


% =============================================================================
% E. IMAGE COMPOSITION AND BLENDING
% =============================================================================

% Poisson Image Editing - Seamless blending in effects service
@Article{perez2003poisson,
    author    = {P\'{e}rez, Patrick and Gangnet, Michel and Blake, Andrew},
    title     = {Poisson Image Editing},
    journal   = {ACM Transactions on Graphics},
    volume    = {22},
    number    = {3},
    pages     = {313--318},
    year      = {2003},
    doi       = {10.1145/882262.882269}
}

% Laplacian Pyramid - Multiresolution representation
@Article{burt1983laplacian,
    author    = {Burt, Peter J. and Adelson, Edward H.},
    title     = {The Laplacian Pyramid as a Compact Image Code},
    journal   = {IEEE Transactions on Communications},
    volume    = {31},
    number    = {4},
    pages     = {532--540},
    year      = {1983},
    doi       = {10.1109/TCOM.1983.1095851}
}

% Multiresolution Spline - Laplacian pyramid blending in effects service
@Article{burt1983spline,
    author    = {Burt, Peter J. and Adelson, Edward H.},
    title     = {A Multiresolution Spline With Application to Image Mosaics},
    journal   = {ACM Transactions on Graphics},
    volume    = {2},
    number    = {4},
    pages     = {217--236},
    year      = {1983},
    doi       = {10.1145/245.247}
}

% Color Transfer - LAB color space transfer
@Article{reinhard2001color,
    author    = {Reinhard, Erik and Ashikhmin, Michael and Gooch, Bruce and Shirley, Peter},
    title     = {Color Transfer between Images},
    journal   = {IEEE Computer Graphics and Applications},
    volume    = {21},
    number    = {5},
    pages     = {34--41},
    year      = {2001},
    doi       = {10.1109/38.946629}
}


% =============================================================================
% F. SYNTHETIC DATA AND DOMAIN ADAPTATION
% =============================================================================

% Domain Randomization - Core technique in domain_gap service
@InProceedings{tobin2017domain,
    author    = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
    title     = {Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World},
    booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    pages     = {23--30},
    year      = {2017},
    doi       = {10.1109/IROS.2017.8202133},
    note      = {arXiv:1703.06907}
}

% Domain Randomization + Pyramid Consistency
@InProceedings{yue2019domain,
    author    = {Yue, Xiangyu and Zhang, Yang and Zhao, Sicheng and Sangiovanni-Vincentelli, Alberto and Keutzer, Kurt and Gong, Boqing},
    title     = {Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization Without Accessing Target Domain Data},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2019},
    note      = {arXiv:1909.00889}
}

% Training with Synthetic Data - Bridging the reality gap
@InProceedings{tremblay2018training,
    author    = {Tremblay, Jonathan and Prakash, Aayush and Acuna, David and Brophy, Mark and Jampani, Varun and Anil, Cem and To, Thang and Cameracci, Eric and Boochoon, Shaad and Birchfield, Stan},
    title     = {Training Deep Networks With Synthetic Data: Bridging the Reality Gap by Domain Randomization},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    year      = {2018},
    note      = {arXiv:1804.06516}
}

% Cut, Paste and Learn - Cut-and-paste composition for detection
@InProceedings{dwibedi2017cut,
    author    = {Dwibedi, Debidatta and Misra, Ishan and Hebert, Martial},
    title     = {Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection},
    booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
    pages     = {1310--1319},
    year      = {2017},
    doi       = {10.1109/ICCV.2017.146},
    note      = {arXiv:1708.01642}
}

% Copy-Paste Augmentation - Instance segmentation augmentation
@InProceedings{ghiasi2021copypaste,
    author    = {Ghiasi, Golnaz and Cui, Yin and Srinivas, Aravind and Qian, Rui and Lin, Tsung-Yi and Cubuk, Ekin D. and Le, Quoc V. and Zoph, Barret},
    title     = {Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {2918--2928},
    year      = {2021},
    doi       = {10.1109/CVPR46437.2021.00294}
}

% Playing for Data - Synthetic data from video games
@InProceedings{richter2016playing,
    author    = {Richter, Stephan R. and Vineet, Vibhav and Roth, Stefan and Koltun, Vladlen},
    title     = {Playing for Data: Ground Truth from Computer Games},
    booktitle = {European Conference on Computer Vision (ECCV)},
    series    = {Lecture Notes in Computer Science},
    volume    = {9906},
    pages     = {102--118},
    publisher = {Springer International Publishing},
    year      = {2016},
    doi       = {10.1007/978-3-319-46475-6_7},
    note      = {arXiv:1608.02192}
}


% =============================================================================
% G. DATA AUGMENTATION
% =============================================================================

% Data Augmentation Survey
@Article{shorten2019survey,
    author    = {Shorten, Connor and Khoshgoftaar, Taghi M.},
    title     = {A Survey on Image Data Augmentation for Deep Learning},
    journal   = {Journal of Big Data},
    volume    = {6},
    number    = {1},
    pages     = {1--48},
    year      = {2019},
    publisher = {Springer},
    doi       = {10.1186/s40537-019-0197-0}
}

% MixUp
@InProceedings{zhang2018mixup,
    author    = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
    title     = {mixup: Beyond Empirical Risk Minimization},
    booktitle = {International Conference on Learning Representations (ICLR)},
    year      = {2018},
    url       = {https://openreview.net/forum?id=r1Ddp1-Rb},
    note      = {arXiv:1710.09412}
}

% CutMix
@InProceedings{yun2019cutmix,
    author    = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
    title     = {{CutMix}: Regularization Strategy to Train Strong Classifiers with Localizable Features},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    pages     = {6023--6032},
    year      = {2019},
    doi       = {10.1109/ICCV.2019.00612},
    note      = {arXiv:1905.04899}
}


% =============================================================================
% H. DATASETS AND BENCHMARKS
% =============================================================================

% MS COCO - Main dataset format
@InProceedings{lin2014coco,
    author    = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll\'{a}r, Piotr and Zitnick, C. Lawrence},
    title     = {Microsoft {COCO}: Common Objects in Context},
    booktitle = {Computer Vision -- ECCV 2014},
    editor    = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
    publisher = {Springer International Publishing},
    pages     = {740--755},
    year      = {2014},
    doi       = {10.1007/978-3-319-10602-1\_48},
    note      = {arXiv:1405.0312}
}

% PASCAL VOC - Supported export format
@Article{everingham2010voc,
    author    = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
    title     = {The {PASCAL} Visual Object Classes ({VOC}) Challenge},
    journal   = {International Journal of Computer Vision},
    volume    = {88},
    number    = {2},
    pages     = {303--338},
    year      = {2010},
    doi       = {10.1007/s11263-009-0275-4}
}

% ImageNet - Pre-training dataset for networks used
@InProceedings{deng2009imagenet,
    author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
    title     = {{ImageNet}: A Large-Scale Hierarchical Image Database},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {248--255},
    year      = {2009},
    doi       = {10.1109/CVPR.2009.5206848}
}

% Underwater Image Enhancement Benchmark
@Article{li2020underwater,
    author    = {Li, Chongyi and Guo, Chunle and Ren, Wenqi and Cong, Runmin and Hou, Junhui and Kwong, Sam and Tao, Dacheng},
    title     = {An Underwater Image Enhancement Benchmark Dataset and Beyond},
    journal   = {IEEE Transactions on Image Processing},
    volume    = {29},
    pages     = {4376--4389},
    year      = {2020},
    doi       = {10.1109/TIP.2019.2955241}
}


% =============================================================================
% I. OBJECT DETECTION
% =============================================================================

% YOLO - Supported export format
@InProceedings{redmon2016yolo,
    author    = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
    title     = {You Only Look Once: Unified, Real-Time Object Detection},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages     = {779--788},
    year      = {2016},
    doi       = {10.1109/CVPR.2016.91}
}

% SSD
@InProceedings{liu2016ssd,
    author    = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
    title     = {{SSD}: Single Shot MultiBox Detector},
    booktitle = {European Conference on Computer Vision (ECCV)},
    series    = {Lecture Notes in Computer Science},
    volume    = {9905},
    pages     = {21--37},
    publisher = {Springer International Publishing},
    year      = {2016},
    doi       = {10.1007/978-3-319-46448-0_2}
}

% Faster R-CNN
@InProceedings{ren2015faster,
    author    = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
    title     = {Faster {R-CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    volume    = {28},
    pages     = {91--99},
    year      = {2015},
    note      = {arXiv:1506.01497}
}


% =============================================================================
% J. NETWORK ARCHITECTURES AND TRAINING
% =============================================================================

% Inception-v3 - Feature extractor for FID/KID
@InProceedings{szegedy2016rethinking,
    author    = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
    title     = {Rethinking the Inception Architecture for Computer Vision},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2016},
    pages     = {2818--2826},
    doi       = {10.1109/CVPR.2016.308}
}

% ResNet - Backbone for multiple models
@InProceedings{he2016deep,
    author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    title     = {Deep Residual Learning for Image Recognition},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2016},
    pages     = {770--778},
    doi       = {10.1109/CVPR.2016.90}
}

% FPN - Feature Pyramid Networks
@InProceedings{lin2017feature,
    author    = {Lin, Tsung-Yi and Doll\'{a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
    title     = {Feature Pyramid Networks for Object Detection},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {July},
    year      = {2017},
    pages     = {2117--2125},
    doi       = {10.1109/CVPR.2017.106}
}

% Batch Normalization
@InProceedings{ioffe2015batch,
    author    = {Ioffe, Sergey and Szegedy, Christian},
    title     = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
    booktitle = {Proceedings of the 32nd International Conference on Machine Learning (ICML)},
    series    = {Proceedings of Machine Learning Research},
    volume    = {37},
    pages     = {448--456},
    year      = {2015},
    publisher = {PMLR},
    note      = {arXiv:1502.03167}
}


% =============================================================================
% K. TOOLS AND LIBRARIES
% =============================================================================

% OpenCV - Main image processing library
@Article{bradski2000opencv,
    author    = {Bradski, G.},
    title     = {The {OpenCV} Library},
    journal   = {Dr. Dobb's Journal of Software Tools},
    volume    = {25},
    number    = {11},
    pages     = {120--125},
    year      = {2000}
}

% HuggingFace Transformers - Model framework for segmentation
@InProceedings{wolf2020transformers,
    author    = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R\'{e}mi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
    title     = {Transformers: State-of-the-Art Natural Language Processing},
    booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
    month     = {October},
    year      = {2020},
    publisher = {Association for Computational Linguistics},
    pages     = {38--45},
    url       = {https://aclanthology.org/2020.emnlp-demos.6}
}


% =============================================================================
% L. DISTANCE METRICS AND OPTIMIZATION
% =============================================================================

% Earth Mover's Distance - Color distribution comparison
@Article{rubner2000emd,
    author    = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J.},
    title     = {The Earth Mover's Distance as a Metric for Image Retrieval},
    journal   = {International Journal of Computer Vision},
    volume    = {40},
    number    = {2},
    pages     = {99--121},
    year      = {2000},
    doi       = {10.1023/A:1026543900054}
}

% Adam optimizer - Used in CycleGAN and style transfer training
@InProceedings{kingma2015adam,
    author    = {Kingma, Diederik P. and Ba, Jimmy},
    title     = {Adam: A Method for Stochastic Optimization},
    booktitle = {Proceedings of the 3rd International Conference on Learning Representations (ICLR)},
    year      = {2015},
    note      = {arXiv:1412.6980}
}
